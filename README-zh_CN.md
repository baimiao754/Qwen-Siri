通过快捷指令，将截屏的图片发送给通义的api，或将截屏后提取的文本发送给通义的api或chatglm的api，实现ai对屏幕内容或图片内容的理解和阅读。

快捷指令链接：https://www.icloud.com/shortcuts/d981fedba4fc42a4a67bec0d40d68566

操作步骤：
1.https://bailian.console.aliyun.com/?apiKey=1#/api-key（通义千问apikey获取地址）
https://bigmodel.cn/usercenter/proj-mgmt/apikeys
（chatglm的apikey获取地址）
将获取到的key分别填入列表中，一定要按照顺序填入，顺序不对将无法运行。

2.选择要调用的模型，默认为3，如果要使用图片识别功能请选择2（用的阿里的两个模型分别为qwen-vl-plus-latest和qwen-plus-1127，主要有免费的token额度，可以自己替换为阿里的其他模型）（有vl为图片理解模型，没有vl的为普通大模型）

3.选择1或3的模型调用也可以使用图片识别功能，但因为是通过对截屏内的文字进行提取后发给大模型，所以无法识别纯图片。

4.显示输出结果页面，取消按钮为关闭快捷指令，完成按钮为继续聊天，可以提问图片的更多详细问题（以及默认开启模型联网功能，如有需要，可自行关闭）

5.可以将快捷指令加入控制中心，控制中心中添加快捷指令按钮，选择智能识图，便可以实现在控制中心点击按钮后对当前页面进行识别。

6.输入以“识别”开头的任何文本，或输入“新聊天”，将会重新开始聊天。输入“退出聊天”将会退出聊天。

7.其他参数可自行设置。

8.在制作过程中，意识到大模型的图片识别功能可以帮助视障群体看到手机上的媒体和图片内容，故加入视障模式开关，该模型将会更详细的描述图片内容，并在输出结果前给予振动提示，如有需要，可以打开。

该快捷指令基于@乐阳YueYang大佬项目改进而成，原项目地址https://github.com/Yue-Yang/ChatGPT-Siri，请支持原项目作者。
